{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from functools import reduce\n",
    "from operator import __add__\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from constants import INITIAL_KERNEL_NUM, MIN_DROPOUT, MAX_DROPOUT, CONV1_KERNEL1, CONV1_KERNEL2\n",
    "\n",
    "# +\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import INITIAL_KERNEL_NUM, MIN_DROPOUT, MAX_DROPOUT, CONV1_KERNEL1, CONV1_KERNEL2\n",
    "\n",
    "# +\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self,in_channel,out_channel,expansion,activation,stride=1,padding = 1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.stride=stride\n",
    "        self.conv1 = nn.Conv1d(in_channel,in_channel*expansion,kernel_size = 1)\n",
    "        self.conv2 = nn.Conv1d(in_channel*expansion,in_channel*expansion,kernel_size = 3, groups = in_channel*expansion,\n",
    "                               padding=padding,stride = stride)\n",
    "        self.conv3 = nn.Conv1d(in_channel*expansion,out_channel,kernel_size = 1, stride =1)\n",
    "        self.b0 = nn.BatchNorm1d(in_channel*expansion)\n",
    "        self.b1 =  nn.BatchNorm1d(in_channel*expansion)\n",
    "        self.d = nn.Dropout()\n",
    "        self.act = activation()\n",
    "    def forward(self,x):\n",
    "        if self.stride == 1:\n",
    "            y = self.act(self.b0(self.conv1(x)))\n",
    "            y = self.act(self.b1(self.conv2(y)))\n",
    "            y = self.conv3(y)\n",
    "            y = self.d(y)\n",
    "            y = x+y\n",
    "            return y\n",
    "        else:\n",
    "            y = self.act(self.b0(self.conv1(x)))\n",
    "            y = self.act(self.b1(self.conv2(y)))\n",
    "            y = self.conv3(y)\n",
    "            return y\n",
    "\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(self,in_channel,out_channels,expansion,layers,activation=nn.ReLU6,stride = 2):\n",
    "        super(MBConv, self).__init__()\n",
    "        self.stack = OrderedDict()\n",
    "        for i in range(0,layers-1):\n",
    "            self.stack['s'+str(i)] = Bottleneck(in_channel,in_channel,expansion,activation)\n",
    "            #self.stack['a'+str(i)] = activation()\n",
    "        self.stack['s'+str(layers+1)] = Bottleneck(in_channel,out_channels,expansion,activation,stride=stride)\n",
    "        # self.stack['a'+str(layers+1)] = activation()\n",
    "        self.stack = nn.Sequential(self.stack)\n",
    "        \n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "    def forward(self,x):\n",
    "        x = self.stack(x)\n",
    "        return self.bn(x)\n",
    "\n",
    "\n",
    "\"\"\"def MBConv(in_channel,out_channels,expansion,layers,activation=nn.ReLU6,stride = 2):\n",
    "    stack = OrderedDict()\n",
    "    for i in range(0,layers-1):\n",
    "        stack['b'+str(i)] = Bottleneck(in_channel,in_channel,expansion,activation)\n",
    "    stack['b'+str(layers)] = Bottleneck(in_channel,out_channels,expansion,activation,stride=stride)\n",
    "    return nn.Sequential(stack)\"\"\"\n",
    "\n",
    "\n",
    "class EffNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,num_additional_features = 0,depth = [1,2,2,3,3,3,3],channels = [32,16,24,40,80,112,192,320,1280,1867],\n",
    "                dilation = 1,stride = 2,expansion = 6,hook=False,multi=False,reg=False, start_channels=12, multi_class=False):\n",
    "        super(EffNet, self).__init__()\n",
    "        print(\"depth \",depth)\n",
    "        self.stage1 = nn.Conv1d(start_channels, channels[0], kernel_size=3, stride=stride, padding=1,dilation = dilation) #1 conv\n",
    "        self.b0 = nn.BatchNorm1d(channels[0])\n",
    "        self.stage2 = MBConv(channels[0], channels[1], expansion, depth[0], stride=2)# 16 #input, output, depth # 3 conv\n",
    "        self.stage3 = MBConv(channels[1], channels[2], expansion, depth[1], stride=2)# 24 # 4 conv # d 2\n",
    "        self.Pool = nn.MaxPool1d(3, stride=1, padding=1) # \n",
    "        self.stage4 = MBConv(channels[2], channels[3], expansion, depth[2], stride=2)# 40 # 4 conv # d 2\n",
    "        self.stage5 = MBConv(channels[3], channels[4], expansion, depth[3], stride=2)# 80 # 5 conv # d\n",
    "        self.stage6 = MBConv(channels[4], channels[5], expansion, depth[4], stride=2)# 112 # 5 conv\n",
    "        self.stage7 = MBConv(channels[5], channels[6], expansion, depth[5], stride=2)# 192 # 5 conv\n",
    "        self.stage8 = MBConv(channels[6], channels[7], expansion, depth[6], stride=2)# 320 # 5 conv\n",
    "        \n",
    "        self.stage9 = nn.Conv1d(channels[7], channels[8], kernel_size=1)\n",
    "        self.AAP = nn.AdaptiveAvgPool1d(1)\n",
    "        self.act = nn.ReLU()\n",
    "        self.drop = nn.Dropout()\n",
    "        self.num_additional_features = num_additional_features\n",
    "        self.fc = nn.Linear(channels[8] + num_additional_features, channels[9])\n",
    "        self.fc.bias.data[0] = 0.275\n",
    "        self.multi_class= multi_class\n",
    "        \n",
    "        self.hook = hook\n",
    "        self.multi = multi\n",
    "        self.reg = reg\n",
    "    def forward(self, x):\n",
    "        if self.num_additional_features >0:\n",
    "            x,additional = x\n",
    "        # N x 12 x 2500\n",
    "        x = self.b0(self.stage1(x))\n",
    "        # N x 32 x 1250\n",
    "        x = self.stage2(x)\n",
    "        # N x 16 x 625\n",
    "        x = self.stage3(x)\n",
    "        # N x 24 x 313\n",
    "        x = self.Pool(x)\n",
    "        # N x 24 x 313\n",
    "        \n",
    "        x = self.stage4(x)\n",
    "        # N x 40 x 157\n",
    "        x = self.stage5(x)\n",
    "        # N x 80 x 79\n",
    "        x = self.stage6(x)\n",
    "        # N x 112 x 40\n",
    "        x = self.Pool(x)\n",
    "        # N x 192 x 20\n",
    "        \n",
    "        x = self.stage7(x)\n",
    "        # N x 320 x 10\n",
    "        x = self.stage8(x)\n",
    "        x = self.stage9(x)\n",
    "        # N x 1280 x 10\n",
    "        x = self.act(self.AAP(x)[:,:,0])\n",
    "        # N x 1280\n",
    "        x = self.drop(x)\n",
    "        if self.num_additional_features >0:\n",
    "            x = torch.cat((x,additional),1)\n",
    "        if self.hook:\n",
    "            return x\n",
    "        x = self.fc(x)\n",
    "        # N x 1\n",
    "        if self.reg:\n",
    "            return x\n",
    "        if self.multi_class:\n",
    "            return torch.softmax(x, dim=1)\n",
    "        return torch.sigmoid(x) #Use sigmoid for binary classification and softmax for multi-class classification\n",
    "# -\n",
    "\n",
    "\n",
    "\n",
    "# # use trial.suggest from optuna to suggest hyperparameters \n",
    "# # https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        conv_padding = reduce(__add__, [(k // 2 + (k - 2 * (k // 2)) - 1, k // 2) for k in kernel_size[::-1]])\n",
    "        self.pad = nn.ZeroPad2d(conv_padding)\n",
    "        # ZeroPad2d Output: :math:`(N, C, H_{out}, W_{out})` H_{out} is H_{in} with the padding to be added to either side of height\n",
    "        # ZeroPad2d(2) would add 2 to all 4 sides, ZeroPad2d((1,1,2,0)) would add 1 left, 1 right, 2 above, 0 below\n",
    "        # n_output_features = floor((n_input_features + 2(paddingsize) - convkernel_size) / stride_size) + 1\n",
    "        # above creates same padding\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        x = self.conv(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# +\n",
    "def output_channels(num):\n",
    "    return int(num / 3) + int(num) + int(num) + int(num / 3)\n",
    "\n",
    "class Multi_2D_CNN_block(nn.Module):\n",
    "    def __init__(self, in_channels, num_kernel):\n",
    "        super(Multi_2D_CNN_block, self).__init__()\n",
    "        conv_block = BasicConv2d\n",
    "        self.a = conv_block(in_channels, int(num_kernel / 3), kernel_size=(1, 1))\n",
    "\n",
    "        self.b = nn.Sequential(\n",
    "            conv_block(in_channels, int(num_kernel / 2), kernel_size=(1, 1)),\n",
    "            conv_block(int(num_kernel / 2), int(num_kernel), kernel_size=(3, 3))\n",
    "        )\n",
    "\n",
    "        self.c = nn.Sequential(\n",
    "            conv_block(in_channels, int(num_kernel / 3), kernel_size=(1, 1)),\n",
    "            conv_block(int(num_kernel / 3), int(num_kernel / 2), kernel_size=(3, 3)),\n",
    "            conv_block(int(num_kernel / 2), int(num_kernel), kernel_size=(3, 3))\n",
    "        )\n",
    "        self.d = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, int(num_kernel / 3),kernel_size=(1, 1)),\n",
    "            nn.MaxPool2d(kernel_size=(3, 3),padding=(1,1),stride = 1)\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.out_channels = output_channels(num_kernel)\n",
    "        \n",
    "        # I get out_channels is total number of out_channels for a/b/c\n",
    "        self.bn = nn.BatchNorm2d(self.out_channels)\n",
    "\n",
    "    def get_out_channels(self):\n",
    "        return self.out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.a(x)\n",
    "        branch2 = self.b(x)\n",
    "        branch3 = self.c(x)\n",
    "        branch4 = self.d(x)\n",
    "        output = [branch1, branch2, branch3,branch4]\n",
    "        final = self.bn(torch.cat(output,\n",
    "                                 1))  # BatchNorm across the concatenation of output channels from final layer of Branch 1/2/3\n",
    "        return final\n",
    "        # ,1 refers to the channel dimension\n",
    "# -\n",
    "\n",
    "\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        conv_padding = reduce(__add__, [(k // 2 + (k - 2 * (k // 2)) - 1, k // 2) for k in kernel_size[::-1]])\n",
    "        self.pad = nn.ZeroPad2d(conv_padding)\n",
    "        # ZeroPad2d Output: :math:`(N, C, H_{out}, W_{out})` H_{out} is H_{in} with the padding to be added to either side of height\n",
    "        # ZeroPad2d(2) would add 2 to all 4 sides, ZeroPad2d((1,1,2,0)) would add 1 left, 1 right, 2 above, 0 below\n",
    "        # n_output_features = floor((n_input_features + 2(paddingsize) - convkernel_size) / stride_size) + 1\n",
    "        # above creates same padding\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        x = self.conv(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self,trial = None, inital_kernel_num = None,dropout = None,conv1kernel1 = None,conv1kernel2 = None,reduced = False,num_additional_features=0):# trial, inital_kernel_num,dropout,conv1kernel1,conv1kernel2\n",
    "        super(MyModel, self).__init__()\n",
    "        multi_2d_cnn = Multi_2D_CNN_block\n",
    "        conv_block = BasicConv2d\n",
    "        # Define the values in constants.py and import them\n",
    "        if not trial is None:\n",
    "            initial_kernel_num = trial.suggest_categorical(\"kernel_num\", INITIAL_KERNEL_NUM)\n",
    "            dropout = trial.suggest_float('dropout', MIN_DROPOUT, MAX_DROPOUT)\n",
    "            conv1kernel1 = trial.suggest_categorical(\"conv_1_1\", CONV1_KERNEL1)\n",
    "            conv1kernel2 = trial.suggest_categorical(\"conv_1_2\", CONV1_KERNEL2)\n",
    "        elif not inital_kernel_num is None:\n",
    "            initial_kernel_num = inital_kernel_num\n",
    "            dropout = dropout\n",
    "            conv1kernel1 = conv1kernel1\n",
    "            conv1kernel2 = conv1kernel2\n",
    "            self.num_additional_features = num_additional_features\n",
    "        \n",
    "\n",
    "        self.conv_1 = conv_block(1, 64, kernel_size=(conv1kernel1, conv1kernel2), stride=(2, 1)) #kernel_size=(7,1), (21,3), (21,1)....\n",
    "        \n",
    "        self.multi_2d_cnn_1a = nn.Sequential(\n",
    "            multi_2d_cnn(in_channels=64, num_kernel=initial_kernel_num),\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num), num_kernel=initial_kernel_num),\n",
    "            nn.MaxPool2d(kernel_size=(3, 1))\n",
    "        )\n",
    "        \n",
    "        num_kernel=initial_kernel_num\n",
    "        self.path_1 = nn.Sequential(\n",
    "            nn.Conv2d(64, output_channels(initial_kernel_num), kernel_size=(1, 1), stride=(3, 1)),\n",
    "            \n",
    "            nn.BatchNorm2d(output_channels(initial_kernel_num))\n",
    "        )\n",
    "        self.multi_2d_cnn_1b = nn.Sequential(\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num), num_kernel=initial_kernel_num * 1.5),\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num*1.5), num_kernel=initial_kernel_num * 1.5),\n",
    "            nn.MaxPool2d(kernel_size=(3, 1))\n",
    "        )\n",
    "        self.path_2 = nn.Sequential(\n",
    "            nn.Conv2d(output_channels(initial_kernel_num), output_channels(initial_kernel_num * 1.5), kernel_size=(1, 1), stride=(3, 1)),\n",
    "            \n",
    "            nn.BatchNorm2d(output_channels(initial_kernel_num * 1.5))\n",
    "        )\n",
    "        self.multi_2d_cnn_1c = nn.Sequential(\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num * 1.5), num_kernel=initial_kernel_num * 2),\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num * 2), num_kernel=initial_kernel_num * 2),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        )\n",
    "        self.path_3 = nn.Sequential(\n",
    "            nn.Conv2d(output_channels(initial_kernel_num * 1.5), output_channels(initial_kernel_num * 2), kernel_size=(1, 1), stride=(2, 1)),\n",
    "            \n",
    "            nn.BatchNorm2d(output_channels(initial_kernel_num * 2))\n",
    "        )\n",
    "        \n",
    "        self.multi_2d_cnn_2a = nn.Sequential(\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num * 2), num_kernel=initial_kernel_num * 3),\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num * 3), num_kernel=initial_kernel_num * 3),\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num * 3), num_kernel=initial_kernel_num * 4),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        )\n",
    "        self.path_4 = nn.Sequential(\n",
    "            nn.Conv2d(output_channels(initial_kernel_num * 2), output_channels(initial_kernel_num * 4), kernel_size=(1, 1), stride=(2, 1)),\n",
    "            \n",
    "            nn.BatchNorm2d(output_channels(initial_kernel_num * 4))\n",
    "        )\n",
    "        \n",
    "        self.multi_2d_cnn_2b = nn.Sequential(\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num * 4), num_kernel=initial_kernel_num * 5),\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num * 5), num_kernel=initial_kernel_num * 6),\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num * 6), num_kernel=initial_kernel_num * 7),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        )\n",
    "\n",
    "        self.path_5 = nn.Sequential(\n",
    "            nn.Conv2d(output_channels(initial_kernel_num * 4), output_channels(initial_kernel_num * 7), kernel_size=(1, 1), stride=(2, 1)),\n",
    "            \n",
    "            nn.BatchNorm2d(output_channels(initial_kernel_num * 7))\n",
    "        )\n",
    "        \n",
    "        self.multi_2d_cnn_2c = nn.Sequential(\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num * 7), num_kernel=initial_kernel_num * 8),\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num * 8), num_kernel=initial_kernel_num * 8),\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num * 8), num_kernel=initial_kernel_num * 8),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        )\n",
    "\n",
    "        self.path_6 = nn.Sequential(\n",
    "            nn.Conv2d(output_channels(initial_kernel_num * 7), output_channels(initial_kernel_num * 8), kernel_size=(1, 1), stride=(2, 1)),\n",
    "            \n",
    "            nn.BatchNorm2d(output_channels(initial_kernel_num * 8))\n",
    "        )\n",
    "        self.multi_2d_cnn_2d = nn.Sequential(\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num * 8), num_kernel=initial_kernel_num * 12),\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num * 12), num_kernel=initial_kernel_num * 14),\n",
    "            multi_2d_cnn(in_channels=output_channels(initial_kernel_num * 14), num_kernel=initial_kernel_num * 16),\n",
    "        )\n",
    "\n",
    "        self.path_7 = nn.Sequential(\n",
    "            nn.Conv2d(output_channels(initial_kernel_num * 8), output_channels(initial_kernel_num * 16), kernel_size=(1, 1), stride=(1, 1)),\n",
    "            \n",
    "            nn.BatchNorm2d(output_channels(initial_kernel_num * 16))\n",
    "        )\n",
    "        neurons = (output_channels(initial_kernel_num * 16))\n",
    "\n",
    "        self.p1 = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.f1 = nn.Flatten()\n",
    "        self.d1 = nn.Dropout(dropout)\n",
    "        self.l1 = nn.Linear(neurons+self.num_additional_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # N x 1 x 2500 x 12 -> N x 2500 x 12\n",
    "        if x.shape[2]==2500:\n",
    "            reduced = True\n",
    "        else:\n",
    "            reduced = False\n",
    "        x = self.conv_1(x)\n",
    "        # N x 64 x 1250 x 12 tensor -> N x 1250 x\n",
    "        y = self.path_1(x)[:, :, :-1, :]\n",
    "        \n",
    "        x = self.multi_2d_cnn_1a(x)\n",
    "        x = x+y\n",
    "        # N x 74 x 416 x 12 tensor\n",
    "        y = self.path_2(x)[:, :, :-1, :]\n",
    "        x = self.multi_2d_cnn_1b(x)\n",
    "        x = x+y\n",
    "        # N x 112 x 138 x 12 tensor\n",
    "        if reduced:\n",
    "            y = self.path_3(x)\n",
    "        else:\n",
    "            y = self.path_3(x)[:, :, :-1, :]\n",
    "        x = self.multi_2d_cnn_1c(x)\n",
    "        # N x 149 x 69 x 12\n",
    "        x = x+y\n",
    "        if reduced:\n",
    "            y = self.path_4(x)[:, :, :-1, :]\n",
    "        else:\n",
    "            y = self.path_4(x)\n",
    "        x = self.multi_2d_cnn_2a(x)\n",
    "        x = x+y\n",
    "        # N x 298 x 69 x 12\n",
    "        if reduced:\n",
    "            y = self.path_5(x)\n",
    "        else:\n",
    "            y = self.path_5(x)[:, :, :-1, :]\n",
    "        x = self.multi_2d_cnn_2b(x)\n",
    "        x = x+y\n",
    "        # N x 522 x 17 x 12\n",
    "        if reduced:\n",
    "            y = self.path_6(x)[:, :, :-1, :]\n",
    "        else:\n",
    "            y = self.path_6(x)\n",
    "        x = self.multi_2d_cnn_2c(x)\n",
    "        x = x+y\n",
    "        # N x 597 x 8 x 12\n",
    "        y = self.path_7(x)\n",
    "        x = self.multi_2d_cnn_2d(x)\n",
    "        x = x+y\n",
    "        # N x 1194 x 8 x 12\n",
    "        \n",
    "        # print(x.shape,self.shortcut(x).shape)\n",
    "        # print(torch.sum(x[0,0,:,:])/(8*12),self.shortcut(x)[0,0,0,0])\n",
    "        x = self.p1(x)\n",
    "        x = self.f1(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.l1(x)\n",
    "        # x = self.output(x)\n",
    "        # N x 1\n",
    "        return x\n",
    "\n",
    "\n",
    "class Mayo_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mayo_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(12,16,5,padding=2)#nn.Conv1d(12,16,5)\n",
    "        self.batch1 = nn.BatchNorm1d(16)\n",
    "        self.pool1 = nn.MaxPool1d(2,1) \n",
    "        self.conv2 = nn.Conv1d(16,16,5,padding=2)\n",
    "        self.conv3 = nn.Conv1d(16,32,5,padding=4)\n",
    "        self.batch3 = nn.BatchNorm1d(32)\n",
    "        self.pool3 = nn.MaxPool1d(4,1)\n",
    "        self.conv4 = nn.Conv1d(32,32,3,padding=2)\n",
    "        self.conv5 = nn.Conv1d(32,64,3,padding=3)\n",
    "        self.batch5 = nn.BatchNorm1d(64)\n",
    "        self.conv6 = nn.Conv1d(64,64,3,padding=3)\n",
    "        self.conv7 = nn.Conv1d(13344,64,3)\n",
    "        self.conv8 = nn.Conv1d(64,64,3)\n",
    "        self.drop = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(8*64, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.missed = 0\n",
    "        self.total = 0\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = F.relu(self.pool1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch1(x)\n",
    "        x = F.relu(self.pool1(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch3(x)\n",
    "        x = F.relu(self.pool3(x))\n",
    "        x = self.conv4(x)\n",
    "        x = self.batch3(x)\n",
    "        x = F.relu(self.pool1(x))\n",
    "        x = self.conv5(x)\n",
    "        x = self.batch5(x)\n",
    "        x = F.relu(self.pool3(x))\n",
    "        x = self.conv6(x)\n",
    "        x = self.batch5(x)\n",
    "        x = F.relu(self.pool3(x))\n",
    "        x = x.view(-1, 13344,12)\n",
    "        x = self.batch5(self.conv7(self.drop(x)))\n",
    "        x = self.batch5(self.conv8(x))\n",
    "        x = x.view(-1, 64*8)\n",
    "        x = self.drop(F.relu(self.batch5(self.fc1(x))))\n",
    "        x = self.drop(F.relu(self.batch3(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Mayo_Net_mortality(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mayo_Net_mortality, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(12,16,5,padding=2)#nn.Conv1d(12,16,5)\n",
    "        self.batch1 = nn.BatchNorm1d(16)\n",
    "        self.pool1 = nn.MaxPool1d(2,1) \n",
    "        self.conv2 = nn.Conv1d(16,16,5,padding=2)\n",
    "        self.conv3 = nn.Conv1d(16,32,5,padding=4)\n",
    "        self.batch3 = nn.BatchNorm1d(32)\n",
    "        self.pool3 = nn.MaxPool1d(4,1)\n",
    "        self.conv4 = nn.Conv1d(32,32,3,padding=2)\n",
    "        self.conv5 = nn.Conv1d(32,64,3,padding=3)\n",
    "        self.batch5 = nn.BatchNorm1d(64)\n",
    "        self.conv6 = nn.Conv1d(64,64,3,padding=1)\n",
    "        self.conv7 = nn.Conv1d(26656,64,3)\n",
    "        self.conv8 = nn.Conv1d(64,64,3)\n",
    "        self.drop = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(8*64, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.missed = 0\n",
    "        self.total = 0\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = F.relu(self.pool1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch1(x)\n",
    "        x = F.relu(self.pool1(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch3(x)\n",
    "        x = F.relu(self.pool3(x))\n",
    "        x = self.conv4(x)\n",
    "        x = self.batch3(x)\n",
    "        x = F.relu(self.pool1(x))\n",
    "        x = self.conv5(x)\n",
    "        x = self.batch5(x)\n",
    "        x = F.relu(self.pool3(x))\n",
    "        x = self.conv6(x)\n",
    "        x = self.batch5(x)\n",
    "        x = F.relu(self.pool3(x))\n",
    "        x = x.view(-1, 26656,12)\n",
    "        x = self.batch5(self.conv7(self.drop(x)))\n",
    "        x = self.batch5(self.conv8(x))\n",
    "        x = x.view(-1, 64*8)\n",
    "        x = self.drop(F.relu(self.batch5(self.fc1(x))))\n",
    "        x = self.drop(F.relu(self.batch3(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CKD(Mayo_Net,MyModel,EffNet,Bottleneck,MBConv,BasicConv2d,Multi_2D_CNN_block):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = MyModel()\n",
    "        self.model = Mayo_Net()\n",
    "        self.model = EffNet()\n",
    "        self.model = Bottleneck()   \n",
    "        self.model = MBConv()\n",
    "        self.model = BasicConv2d()\n",
    "        self.model = Multi_2D_CNN_block()\n",
    "        self.model = nn.Module()\n",
    "    def forward(self, x):\n",
    "        x=self.bottleneck(x)\n",
    "        x=self.MBConv(x)\n",
    "        x=self.EffNet(x)\n",
    "        x=self.BasicConv2d(x)\n",
    "        x=self.Multi_2D_CNN_block(x)\n",
    "        x=BasicConv2d(x)\n",
    "        x==self.MyModel(x)\n",
    "        x=self.Mayo_Net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CKDModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCKDModel_pickle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mCKDModel\u001b[49m,f)\n\u001b[1;32m      4\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(model, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCKDmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CKDModel' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('CKDModel_pickle','wb') as f:\n",
    "    pickle.dump(CKDModel,f)\n",
    "pickle.dump(model, open('CKDmodel', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
